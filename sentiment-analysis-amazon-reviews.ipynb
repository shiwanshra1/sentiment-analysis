{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1043123,"sourceType":"datasetVersion","datasetId":573774}],"dockerImageVersionId":29985,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"SENTIMENT ANALYSIS | SHIWANSH RAI & SHRUTI NARWAT\n\n## What is sentiment analysis?\nSentiment analysis is the process of using computational methods to determine the sentiment expressed in text, such as positive, negative, or neutral. It involves analyzing opinions, attitudes, and emotions conveyed by the text. This technology is widely used in various fields, including customer feedback analysis, social media monitoring, and market research, to gain insights into public perception and sentiment towards products, services, or events.\n\n\n## Import Libraries\n**Let's import all necessary libraries for the analysis and along with it let's bring down our dataset**\n","metadata":{}},{"cell_type":"code","source":"\n#Basic libraries\nimport pandas as pd \nimport numpy as np \n\n\n#NLTK libraries\nimport nltk\nimport re\nimport string\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Machine Learning libraries\nimport sklearn \nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import BernoulliNB \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn import svm, datasets\nfrom sklearn import preprocessing \n\n\n#Metrics libraries\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\n\n#Visualization libraries\nimport matplotlib.pyplot as plt \nfrom matplotlib import rcParams\nimport seaborn as sns\nfrom textblob import TextBlob\nfrom plotly import tools\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\n%matplotlib inline\n\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Other miscellaneous libraries\nfrom scipy import interp\nfrom itertools import cycle\nimport cufflinks as cf\nfrom collections import defaultdict\nfrom collections import Counter\nfrom imblearn.over_sampling import SMOTE","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:03.785409Z","iopub.execute_input":"2024-06-01T22:52:03.785831Z","iopub.status.idle":"2024-06-01T22:52:03.818915Z","shell.execute_reply.started":"2024-06-01T22:52:03.785795Z","shell.execute_reply":"2024-06-01T22:52:03.817623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing the dataset we are going to apply sentimental analysis on","metadata":{}},{"cell_type":"code","source":"raw_reviews = pd.read_csv('../input/amazon-music-reviews/Musical_instruments_reviews.csv')\n## print shape of dataset with rows and columns and information \nprint (\"The shape of the  data is (row, column):\"+ str(raw_reviews.shape))\nprint (raw_reviews.info())","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:03.822033Z","iopub.execute_input":"2024-06-01T22:52:03.822518Z","iopub.status.idle":"2024-06-01T22:52:03.949290Z","shell.execute_reply.started":"2024-06-01T22:52:03.822478Z","shell.execute_reply":"2024-06-01T22:52:03.948217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:03.951002Z","iopub.execute_input":"2024-06-01T22:52:03.951454Z","iopub.status.idle":"2024-06-01T22:52:03.973060Z","shell.execute_reply.started":"2024-06-01T22:52:03.951395Z","shell.execute_reply":"2024-06-01T22:52:03.971799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Details\n**This file has reviewer ID , User ID, Reviewer Name, Reviewer text, helpful, Summary(obtained from Reviewer text),Overall Rating on a scale 5, Review time**\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# Preprocessing and cleaning of the dataset\n\nPreprocessing and cleaning of the dataset for sentiment analysis involves several steps:\n1. Convert text to lowercase.\n2. Remove noise like punctuation, URLs, and special characters.\n3. Tokenize text into individual words.\n4. Remove stopwords.\n5. Apply stemming or lemmatization.\n6. Handle contractions and numbers.\n7. Address emoticons and emojis.\n8. Optionally, perform spell checking.\n9. Normalize text for consistency.\n\nThese steps ensure that the text data is standardized and ready for sentiment analysis.","metadata":{}},{"cell_type":"code","source":"#Creating a copy\nprocess_reviews=raw_reviews.copy()\n\n#Checking for null values\nprocess_reviews.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:03.974761Z","iopub.execute_input":"2024-06-01T22:52:03.975233Z","iopub.status.idle":"2024-06-01T22:52:04.002430Z","shell.execute_reply.started":"2024-06-01T22:52:03.975185Z","shell.execute_reply":"2024-06-01T22:52:04.001332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have encountered null values in both reviewer names and review text fields. Since reviewer names do not contribute to our project's objective, which focuses on analyzing review text, we will concentrate solely on the review text. While dropping null values might seem acceptable given the small number (only 7), an alternative approach could involve treating these null values as missing data and investigating potential reasons for their absence. One hypothesis worth exploring is whether the absence of reviews is correlated with specific ratings.**","metadata":{}},{"cell_type":"code","source":"process_reviews['reviewText']=process_reviews['reviewText'].fillna('Missing')","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:04.006684Z","iopub.execute_input":"2024-06-01T22:52:04.007076Z","iopub.status.idle":"2024-06-01T22:52:04.017087Z","shell.execute_reply.started":"2024-06-01T22:52:04.007032Z","shell.execute_reply":"2024-06-01T22:52:04.015862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merging Review Text and Summary\nWe will merge the review text and summary columns, as the sentiments expressed in both are expected to align. This consolidation will not result in conflicting sentiments.","metadata":{}},{"cell_type":"code","source":"process_reviews['reviews']=process_reviews['reviewText']+process_reviews['summary']\nprocess_reviews=process_reviews.drop(['reviewText', 'summary'], axis=1)\nprocess_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:04.019290Z","iopub.execute_input":"2024-06-01T22:52:04.020112Z","iopub.status.idle":"2024-06-01T22:52:04.058685Z","shell.execute_reply.started":"2024-06-01T22:52:04.020039Z","shell.execute_reply":"2024-06-01T22:52:04.057368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Establishing the 'Sentiment' Column\nDuring this crucial preprocessing stage, we determine the outcome column (review sentiment) based on the overall score. A score greater than 3 is categorized as positive, while a score less than 3 is considered negative. If the score equals 3, it is interpreted as a neutral sentiment.","metadata":{}},{"cell_type":"code","source":"#Figuring out the distribution of categories\nprocess_reviews['overall'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:04.061600Z","iopub.execute_input":"2024-06-01T22:52:04.062298Z","iopub.status.idle":"2024-06-01T22:52:04.072121Z","shell.execute_reply.started":"2024-06-01T22:52:04.062239Z","shell.execute_reply":"2024-06-01T22:52:04.070783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f(row):\n    \n    '''This function returns sentiment value based on the overall ratings from the user'''\n    \n    if row['overall'] == 3.0:\n        val = 'Neutral'\n    elif row['overall'] == 1.0 or row['overall'] == 2.0:\n        val = 'Negative'\n    elif row['overall'] == 4.0 or row['overall'] == 5.0:\n        val = 'Positive'\n    else:\n        val = -1\n    return val","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:04.074034Z","iopub.execute_input":"2024-06-01T22:52:04.074488Z","iopub.status.idle":"2024-06-01T22:52:04.084630Z","shell.execute_reply.started":"2024-06-01T22:52:04.074449Z","shell.execute_reply":"2024-06-01T22:52:04.082831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Applying the function in our new column\nprocess_reviews['sentiment'] = process_reviews.apply(f, axis=1)\nprocess_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:04.088020Z","iopub.execute_input":"2024-06-01T22:52:04.088961Z","iopub.status.idle":"2024-06-01T22:52:05.043984Z","shell.execute_reply.started":"2024-06-01T22:52:04.088918Z","shell.execute_reply":"2024-06-01T22:52:05.043091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_reviews['sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:05.046999Z","iopub.execute_input":"2024-06-01T22:52:05.047591Z","iopub.status.idle":"2024-06-01T22:52:05.060588Z","shell.execute_reply.started":"2024-06-01T22:52:05.047528Z","shell.execute_reply":"2024-06-01T22:52:05.059315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Managing the Time Column\n\nThe review time column comprises both date and year. Upon splitting these components, we will further divide the date into month and day.","metadata":{}},{"cell_type":"code","source":"# new data frame which has date and year\nnew = process_reviews[\"reviewTime\"].str.split(\",\", n = 1, expand = True) \n  \n# making separate date column from new data frame \nprocess_reviews[\"date\"]= new[0] \n  \n# making separate year column from new data frame \nprocess_reviews[\"year\"]= new[1] \n\nprocess_reviews=process_reviews.drop(['reviewTime'], axis=1)\nprocess_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:05.065477Z","iopub.execute_input":"2024-06-01T22:52:05.066121Z","iopub.status.idle":"2024-06-01T22:52:05.126987Z","shell.execute_reply.started":"2024-06-01T22:52:05.066080Z","shell.execute_reply":"2024-06-01T22:52:05.125886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the date \nnew1 = process_reviews[\"date\"].str.split(\" \", n = 1, expand = True) \n  \n# adding month to the main dataset \nprocess_reviews[\"month\"]= new1[0] \n  \n# adding day to the main dataset \nprocess_reviews[\"day\"]= new1[1] \n\nprocess_reviews=process_reviews.drop(['date'], axis=1)\nprocess_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:05.128705Z","iopub.execute_input":"2024-06-01T22:52:05.129089Z","iopub.status.idle":"2024-06-01T22:52:05.193134Z","shell.execute_reply.started":"2024-06-01T22:52:05.129043Z","shell.execute_reply":"2024-06-01T22:52:05.191635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Determining Review Helpfulness\n\nThe main dataframe includes a 'helpful' feature with values in the format [a, b], indicating that a out of b people found the review helpful. However, this format may not directly contribute to the machine learning model and could be challenging to interpret. To address this, we plan to create a 'helpful_rate' feature, which calculates the ratio a/b from the [a, b] format. The following codeblock outlines the complete processing steps, with comments explaining each action.","metadata":{}},{"cell_type":"code","source":"# Splitting the dataset based on comma and square bracket \nnew1 = process_reviews[\"helpful\"].str.split(\",\", n = 1, expand = True)\nnew2 = new1[0].str.split(\"[\", n = 1, expand = True)\nnew3 = new1[1].str.split(\"]\", n = 1, expand = True)\n\n#Resetting the index\nnew2.reset_index(drop=True, inplace=True)\nnew3.reset_index(drop=True, inplace=True)\n\n#Dropping empty columns due to splitting \nnew2=new2.drop([0], axis=1)\nnew3=new3.drop([1], axis=1)\n\n#Concatenating the splitted columns\nhelpful=pd.concat([new2, new3], axis=1)\n\n\n# I found few spaces in new3, so it is better to strip all the values to find the rate\ndef trim_all_columns(df):\n    \"\"\"\n    Trim whitespace from ends of each value across all series in dataframe\n    \"\"\"\n    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n    return df.applymap(trim_strings)\n\n#Applying the function\nhelpful= trim_all_columns(helpful)\n\n#Converting into integer types\nhelpful[0]=helpful[0].astype(str).astype(int)\nhelpful[1]=helpful[1].astype(str).astype(int)\n\n#Dividing the two columns, we have 0 in the second columns when dvided gives error, so I'm ignoring those errors\ntry:\n  helpful['result'] = helpful[1]/helpful[0]\nexcept ZeroDivisionError:\n  helpful['result']=0\n\n#Filling the NaN values(created due to dividing) with 0\nhelpful['result'] = helpful['result'].fillna(0)\n\n#Rounding of the results to two decimal places\nhelpful['result']=helpful['result'].round(2) \n\n#Attaching the results to a new column of the main dataframe\nprocess_reviews['helpful_rate']=helpful['result']\n\n#dropping the helpful column from main dataframe\nprocess_reviews=process_reviews.drop(['helpful'], axis=1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:05.194909Z","iopub.execute_input":"2024-06-01T22:52:05.195584Z","iopub.status.idle":"2024-06-01T22:52:05.335943Z","shell.execute_reply.started":"2024-06-01T22:52:05.195543Z","shell.execute_reply":"2024-06-01T22:52:05.334941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:05.337469Z","iopub.execute_input":"2024-06-01T22:52:05.338185Z","iopub.status.idle":"2024-06-01T22:52:05.362669Z","shell.execute_reply.started":"2024-06-01T22:52:05.338133Z","shell.execute_reply":"2024-06-01T22:52:05.361375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have successfully created the helpful_rate column through processing steps. Let's look at the values**","metadata":{}},{"cell_type":"code","source":"process_reviews['helpful_rate'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:05.364489Z","iopub.execute_input":"2024-06-01T22:52:05.364909Z","iopub.status.idle":"2024-06-01T22:52:05.377467Z","shell.execute_reply.started":"2024-06-01T22:52:05.364869Z","shell.execute_reply":"2024-06-01T22:52:05.376242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**0.00 indicates that the review hasn't been much helpful and 1.00 indicates that the review has been very helpful**","metadata":{}},{"cell_type":"markdown","source":"## Text Processing: Punctuation Removal\n\nWe'll initiate our text preprocessing by eliminating punctuations.","metadata":{}},{"cell_type":"code","source":"#Removing unnecessary columns\nprocess_reviews=process_reviews.drop(['reviewerName','unixReviewTime'], axis=1)\n#Creating a copy \nclean_reviews=process_reviews.copy()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:05.379329Z","iopub.execute_input":"2024-06-01T22:52:05.379692Z","iopub.status.idle":"2024-06-01T22:52:05.394024Z","shell.execute_reply.started":"2024-06-01T22:52:05.379660Z","shell.execute_reply":"2024-06-01T22:52:05.392987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def review_cleaning(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:05.395932Z","iopub.execute_input":"2024-06-01T22:52:05.396457Z","iopub.status.idle":"2024-06-01T22:52:05.406133Z","shell.execute_reply.started":"2024-06-01T22:52:05.396403Z","shell.execute_reply":"2024-06-01T22:52:05.405160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_reviews['reviews']=process_reviews['reviews'].apply(lambda x:review_cleaning(x))\nprocess_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:05.407453Z","iopub.execute_input":"2024-06-01T22:52:05.407970Z","iopub.status.idle":"2024-06-01T22:52:07.353754Z","shell.execute_reply.started":"2024-06-01T22:52:05.407930Z","shell.execute_reply":"2024-06-01T22:52:07.352507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have removed all punctuation in our review column**","metadata":{}},{"cell_type":"markdown","source":"## Stop Words Handling\n\nFor stop words, the general NLTK stop words list includes words like \"not,\" \"hasn't,\" and \"wouldn't,\" which actually convey negative sentiment. Removing these could contradict the target variable (sentiment). Therefore, I've curated a stop words list that excludes any words with negative sentiment or negative alternatives.","metadata":{}},{"cell_type":"code","source":"stop_words= ['yourselves', 'between', 'whom', 'itself', 'is', \"she's\", 'up', 'herself', 'here', 'your', 'each', \n             'we', 'he', 'my', \"you've\", 'having', 'in', 'both', 'for', 'themselves', 'are', 'them', 'other',\n             'and', 'an', 'during', 'their', 'can', 'yourself', 'she', 'until', 'so', 'these', 'ours', 'above', \n             'what', 'while', 'have', 're', 'more', 'only', \"needn't\", 'when', 'just', 'that', 'were', \"don't\", \n             'very', 'should', 'any', 'y', 'isn', 'who',  'a', 'they', 'to', 'too', \"should've\", 'has', 'before',\n             'into', 'yours', \"it's\", 'do', 'against', 'on',  'now', 'her', 've', 'd', 'by', 'am', 'from', \n             'about', 'further', \"that'll\", \"you'd\", 'you', 'as', 'how', 'been', 'the', 'or', 'doing', 'such',\n             'his', 'himself', 'ourselves',  'was', 'through', 'out', 'below', 'own', 'myself', 'theirs', \n             'me', 'why', 'once',  'him', 'than', 'be', 'most', \"you'll\", 'same', 'some', 'with', 'few', 'it',\n             'at', 'after', 'its', 'which', 'there','our', 'this', 'hers', 'being', 'did', 'of', 'had', 'under',\n             'over','again', 'where', 'those', 'then', \"you're\", 'i', 'because', 'does', 'all']","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:07.355776Z","iopub.execute_input":"2024-06-01T22:52:07.356406Z","iopub.status.idle":"2024-06-01T22:52:07.372905Z","shell.execute_reply.started":"2024-06-01T22:52:07.356333Z","shell.execute_reply":"2024-06-01T22:52:07.371896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_reviews['reviews'] = process_reviews['reviews'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\nprocess_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:07.374245Z","iopub.execute_input":"2024-06-01T22:52:07.374809Z","iopub.status.idle":"2024-06-01T22:52:09.380770Z","shell.execute_reply.started":"2024-06-01T22:52:07.374765Z","shell.execute_reply":"2024-06-01T22:52:09.379868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have removed all the stop words in the review column","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n\n# Story Generation and Visualization from Reviews\n\n**This section focuses on conducting exploratory data analysis on texts and other factors to understand which features contribute to the sentiment.**\n\n**Assumptions for Prior Analysis:**\n* Higher helpful rates indicate positive sentiment.\n* There may be numerous negative sentiment reviews in 2013 and 2014.\n* There could be more reviews at the beginning of each month.\n\n**These assumptions will be validated through our plots, along with extensive text analysis.**","metadata":{}},{"cell_type":"markdown","source":"## Sentiments vs Helpful rate\n**First lets look whether there any relationship between sentiment of review and helpfulness of it**","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(process_reviews.groupby('sentiment')['helpful_rate'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:09.381912Z","iopub.execute_input":"2024-06-01T22:52:09.382384Z","iopub.status.idle":"2024-06-01T22:52:09.396075Z","shell.execute_reply.started":"2024-06-01T22:52:09.382337Z","shell.execute_reply":"2024-06-01T22:52:09.394934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the table we can see that the mean of of helpful rate is higher for any negative reviews than neutral and positive reviews. These mean value might have been influenced by the 0 values in helpful rates. Lets check how it is distributed through violin plot**","metadata":{}},{"cell_type":"code","source":"#plot layout\nplt.rcParams.update({'font.size': 18})\nrcParams['figure.figsize'] = 16,9\n\n# Creating dataframe and removing 0 helpfulrate records\nsenti_help= pd.DataFrame(process_reviews, columns = ['sentiment', 'helpful_rate'])\nsenti_help = senti_help[senti_help['helpful_rate'] != 0.00] \n\n#Plotting phase\nsns.violinplot( x=senti_help[\"sentiment\"], y=senti_help[\"helpful_rate\"])\nplt.title('Sentiment vs Helpfulness')\nplt.xlabel('Sentiment categories')\nplt.ylabel('helpful rate')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:09.397671Z","iopub.execute_input":"2024-06-01T22:52:09.398014Z","iopub.status.idle":"2024-06-01T22:52:09.650527Z","shell.execute_reply.started":"2024-06-01T22:52:09.397982Z","shell.execute_reply":"2024-06-01T22:52:09.649279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insights:** <br>\n\n**From the plot we can declare that more number of positive reviews are having high helpful rate. We got deceived by the mean value, it's better to look at a plot rather than taking some measures of central tendency under such situation. Our first assumption is correct !**","metadata":{}},{"cell_type":"markdown","source":"## Year vs Sentiment count\n**In this block we will see how many reviews were posted based on sentiments in each year from 2004 to 2014**","metadata":{}},{"cell_type":"code","source":"process_reviews.groupby(['year','sentiment'])['sentiment'].count().unstack().plot(legend=True)\nplt.title('Year and Sentiment count')\nplt.xlabel('Year')\nplt.ylabel('Sentiment count')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:09.652124Z","iopub.execute_input":"2024-06-01T22:52:09.652515Z","iopub.status.idle":"2024-06-01T22:52:09.901894Z","shell.execute_reply.started":"2024-06-01T22:52:09.652477Z","shell.execute_reply":"2024-06-01T22:52:09.900538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insights:** <br>\n**From the plot we can clearly see the rise in positive reviews from 2010. Reaching its peak around 2013 and there is a dip in 2014, All the review rates were dropped at this time. Negative and neutral reviews are very low as compared to the positive reviews. Our second assumption is wrong !**","metadata":{}},{"cell_type":"markdown","source":"## Relationship between Day of Month and Review Count\n\nWe'll investigate whether there's any correlation between the number of reviews and the day of the month.","metadata":{}},{"cell_type":"code","source":"#Creating a dataframe\nday=pd.DataFrame(process_reviews.groupby('day')['reviews'].count()).reset_index()\nday['day']=day['day'].astype('int64')\nday.sort_values(by=['day'])\n\n#Plotting the graph\nsns.barplot(x=\"day\", y=\"reviews\", data=day)\nplt.title('Day vs Reviews count')\nplt.xlabel('Day')\nplt.ylabel('Reviews count')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:09.903503Z","iopub.execute_input":"2024-06-01T22:52:09.903893Z","iopub.status.idle":"2024-06-01T22:52:10.364029Z","shell.execute_reply.started":"2024-06-01T22:52:09.903856Z","shell.execute_reply":"2024-06-01T22:52:10.362800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insights:** <br>\n**The review counts are more or less uniformly distributed.There isn't much variance between the days. But there is a huge drop at the end of month. Our third assumption is wrong ! Never trust your instincts unles you do EDA.**","metadata":{}},{"cell_type":"markdown","source":"## Additional Features for Text Analysis\n\nWe'll create the following features:\n1. **Polarity:** Using Textblob to determine the sentiment polarity. It ranges between -1 (negative) and 1 (positive).\n2. **Review Length:** The total length of the review, including letters and spaces.\n3. **Word Count:** The number of words in the review.","metadata":{}},{"cell_type":"code","source":"process_reviews['polarity'] = process_reviews['reviews'].map(lambda text: TextBlob(text).sentiment.polarity)\nprocess_reviews['review_len'] = process_reviews['reviews'].astype(str).apply(len)\nprocess_reviews['word_count'] = process_reviews['reviews'].apply(lambda x: len(str(x).split()))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:10.365613Z","iopub.execute_input":"2024-06-01T22:52:10.365988Z","iopub.status.idle":"2024-06-01T22:52:16.893393Z","shell.execute_reply.started":"2024-06-01T22:52:10.365954Z","shell.execute_reply":"2024-06-01T22:52:16.892487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:16.894777Z","iopub.execute_input":"2024-06-01T22:52:16.895212Z","iopub.status.idle":"2024-06-01T22:52:16.919176Z","shell.execute_reply.started":"2024-06-01T22:52:16.895169Z","shell.execute_reply":"2024-06-01T22:52:16.918191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:16.920633Z","iopub.execute_input":"2024-06-01T22:52:16.920954Z","iopub.status.idle":"2024-06-01T22:52:16.936208Z","shell.execute_reply.started":"2024-06-01T22:52:16.920923Z","shell.execute_reply":"2024-06-01T22:52:16.934937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sentiment polarity distribution\n**Let's look at our polarity distribution**","metadata":{}},{"cell_type":"code","source":"process_reviews['polarity'].iplot(\n    kind='hist',\n    bins=50,\n    xTitle='polarity',\n    linecolor='black',\n    yTitle='count',\n    title='Sentiment Polarity Distribution')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:16.937984Z","iopub.execute_input":"2024-06-01T22:52:16.938528Z","iopub.status.idle":"2024-06-01T22:52:17.314605Z","shell.execute_reply.started":"2024-06-01T22:52:16.938478Z","shell.execute_reply":"2024-06-01T22:52:17.313375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insights:**\n* **We have a lot of positive polarities compared to the negative polarities**\n* **This polarity distributions assures the number of positive reviews we had**\n* **We can say that this polarity is a normally distributed but not standard normal**\n","metadata":{}},{"cell_type":"markdown","source":"## Review Rating Distribution\n**Let's check out how overall ratings are distributed**","metadata":{}},{"cell_type":"code","source":"process_reviews['overall'].iplot(\n    kind='hist',\n    xTitle='rating',\n    linecolor='black',\n    yTitle='count',\n    title='Review Rating Distribution')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:17.316334Z","iopub.execute_input":"2024-06-01T22:52:17.316734Z","iopub.status.idle":"2024-06-01T22:52:17.650655Z","shell.execute_reply.started":"2024-06-01T22:52:17.316691Z","shell.execute_reply":"2024-06-01T22:52:17.649329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have a large number of 5 ratings(nearly 7k) followed by 4,3,2,1. It's linear in nature **","metadata":{}},{"cell_type":"markdown","source":"## Review Text Length Distribution\n**Let's check out the length of review text**","metadata":{}},{"cell_type":"code","source":"process_reviews['review_len'].iplot(\n    kind='hist',\n    bins=100,\n    xTitle='review length',\n    linecolor='black',\n    yTitle='count',\n    title='Review Text Length Distribution')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:17.652554Z","iopub.execute_input":"2024-06-01T22:52:17.653015Z","iopub.status.idle":"2024-06-01T22:52:17.970955Z","shell.execute_reply.started":"2024-06-01T22:52:17.652969Z","shell.execute_reply":"2024-06-01T22:52:17.970030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have a right skewed distribution where most of the lengths falls between 0-1000**","metadata":{}},{"cell_type":"markdown","source":"## Review Text Word Count Distribution\n**Let's check out the word count of review text**","metadata":{}},{"cell_type":"code","source":"process_reviews['word_count'].iplot(\n    kind='hist',\n    bins=100,\n    xTitle='word count',\n    linecolor='black',\n    yTitle='count',\n    title='Review Text Word Count Distribution')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:17.972300Z","iopub.execute_input":"2024-06-01T22:52:17.972901Z","iopub.status.idle":"2024-06-01T22:52:18.277163Z","shell.execute_reply.started":"2024-06-01T22:52:17.972845Z","shell.execute_reply":"2024-06-01T22:52:18.276243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have a right skewed distribution with most of the words falling between 0-200 in a a review** ","metadata":{}},{"cell_type":"markdown","source":"## N-gram Analysis\n\nIn this section, we delve into deep text analysis using n-grams to analyze the text based on its sentiment.","metadata":{}},{"cell_type":"markdown","source":"## Monogram Analysis\n\nIn this section, we'll plot the most frequent one-word occurrences in reviews based on sentiments.","metadata":{}},{"cell_type":"code","source":"#Filtering data\nreview_pos = process_reviews[process_reviews[\"sentiment\"]=='Positive'].dropna()\nreview_neu = process_reviews[process_reviews[\"sentiment\"]=='Neutral'].dropna()\nreview_neg = process_reviews[process_reviews[\"sentiment\"]=='Negative'].dropna()\n\n## custom function for ngram generation ##\ndef generate_ngrams(text, n_gram=1):\n    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n    ngrams = zip(*[token[i:] for i in range(n_gram)])\n    return [\" \".join(ngram) for ngram in ngrams]\n\n## custom function for horizontal bar chart ##\ndef horizontal_bar_chart(df, color):\n    trace = go.Bar(\n        y=df[\"word\"].values[::-1],\n        x=df[\"wordcount\"].values[::-1],\n        showlegend=False,\n        orientation = 'h',\n        marker=dict(\n            color=color,\n        ),\n    )\n    return trace\n\n## Get the bar chart from positive reviews ##\nfreq_dict = defaultdict(int)\nfor sent in review_pos[\"reviews\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted.head(25), 'green')\n\n## Get the bar chart from neutral reviews ##\nfreq_dict = defaultdict(int)\nfor sent in review_neu[\"reviews\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted.head(25), 'grey')\n\n## Get the bar chart from negative reviews ##\nfreq_dict = defaultdict(int)\nfor sent in review_neg[\"reviews\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace2 = horizontal_bar_chart(fd_sorted.head(25), 'red')\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=1, vertical_spacing=0.04,\n                          subplot_titles=[\"Frequent words of positive reviews\", \"Frequent words of neutral reviews\",\n                                          \"Frequent words of negative reviews\"])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\nfig.append_trace(trace2, 3, 1)\nfig['layout'].update(height=1200, width=900, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\niplot(fig, filename='word-plots')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:18.278891Z","iopub.execute_input":"2024-06-01T22:52:18.279276Z","iopub.status.idle":"2024-06-01T22:52:18.876960Z","shell.execute_reply.started":"2024-06-01T22:52:18.279237Z","shell.execute_reply":"2024-06-01T22:52:18.875502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we see, the words doen't match with the sentiment except few. Through monogram we can't judge a sendiment based on one word. So let's try with frequent two words**","metadata":{}},{"cell_type":"markdown","source":"## Bigram Analysis\n\nIn this section, we'll plot the most frequent two-word occurrences in reviews based on sentiments.","metadata":{}},{"cell_type":"code","source":"## Get the bar chart from positive reviews ##\nfreq_dict = defaultdict(int)\nfor sent in review_pos[\"reviews\"]:\n    for word in generate_ngrams(sent,2):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted.head(25), 'green')\n\n## Get the bar chart from neutral reviews ##\nfreq_dict = defaultdict(int)\nfor sent in review_neu[\"reviews\"]:\n    for word in generate_ngrams(sent,2):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted.head(25), 'grey')\n\n## Get the bar chart from negative reviews ##\nfreq_dict = defaultdict(int)\nfor sent in review_neg[\"reviews\"]:\n    for word in generate_ngrams(sent,2):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace2 = horizontal_bar_chart(fd_sorted.head(25), 'brown')\n\n\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=1, vertical_spacing=0.04,horizontal_spacing=0.25,\n                          subplot_titles=[\"Bigram plots of Positive reviews\", \n                                          \"Bigram plots of Neutral reviews\",\n                                          \"Bigram plots of Negative reviews\"\n                                          ])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\nfig.append_trace(trace2, 3, 1)\n\n\nfig['layout'].update(height=1000, width=800, paper_bgcolor='rgb(233,233,233)', title=\"Bigram Plots\")\niplot(fig, filename='word-plots')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:18.878819Z","iopub.execute_input":"2024-06-01T22:52:18.879259Z","iopub.status.idle":"2024-06-01T22:52:19.935011Z","shell.execute_reply.started":"2024-06-01T22:52:18.879214Z","shell.execute_reply":"2024-06-01T22:52:19.934115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Here we can get a clear idea about the sentiments from the bi-words**","metadata":{}},{"cell_type":"markdown","source":"## Trigram analysis\n**Here we will plot most frequent three words in reviews based on sentiments**","metadata":{}},{"cell_type":"code","source":"## Get the bar chart from positive reviews ##\nfor sent in review_pos[\"reviews\"]:\n    for word in generate_ngrams(sent,3):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted.head(25), 'green')\n\n## Get the bar chart from neutral reviews ##\nfreq_dict = defaultdict(int)\nfor sent in review_neu[\"reviews\"]:\n    for word in generate_ngrams(sent,3):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted.head(25), 'grey')\n\n## Get the bar chart from negative reviews ##\nfreq_dict = defaultdict(int)\nfor sent in review_neg[\"reviews\"]:\n    for word in generate_ngrams(sent,3):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace2 = horizontal_bar_chart(fd_sorted.head(25), 'red')\n\n\n\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=1, vertical_spacing=0.04, horizontal_spacing=0.05,\n                          subplot_titles=[\"Tri-gram plots of Positive reviews\", \n                                          \"Tri-gram plots of Neutral reviews\",\n                                          \"Tri-gram plots of Negative reviews\"])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\nfig.append_trace(trace2, 3, 1)\nfig['layout'].update(height=1200, width=1200, paper_bgcolor='rgb(233,233,233)', title=\"Trigram Count Plots\")\niplot(fig, filename='word-plots')\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:19.936345Z","iopub.execute_input":"2024-06-01T22:52:19.936906Z","iopub.status.idle":"2024-06-01T22:52:21.127881Z","shell.execute_reply.started":"2024-06-01T22:52:19.936856Z","shell.execute_reply":"2024-06-01T22:52:21.127034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have completed our text ngram analysis. Let's look at wordcloud **","metadata":{}},{"cell_type":"markdown","source":"## Wordcloud-Positive reviews\n\n**Let's look at the word cloud of positive reviews**","metadata":{}},{"cell_type":"code","source":"text = review_pos[\"reviews\"]\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(text))\nfig = plt.figure(\n    figsize = (40, 30),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:21.129372Z","iopub.execute_input":"2024-06-01T22:52:21.129913Z","iopub.status.idle":"2024-06-01T22:52:31.475297Z","shell.execute_reply.started":"2024-06-01T22:52:21.129864Z","shell.execute_reply":"2024-06-01T22:52:31.473877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can see positive words like great,affordable,expected,exactly etc.,**","metadata":{}},{"cell_type":"markdown","source":"## Wordcloud-Neutral reviews\n\n**Let's look at the word cloud of neutral reviews**","metadata":{}},{"cell_type":"code","source":"text = review_neu[\"reviews\"]\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(text))\nfig = plt.figure(\n    figsize = (40, 30),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:31.476987Z","iopub.execute_input":"2024-06-01T22:52:31.477645Z","iopub.status.idle":"2024-06-01T22:52:41.681030Z","shell.execute_reply.started":"2024-06-01T22:52:31.477587Z","shell.execute_reply":"2024-06-01T22:52:41.679788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Most of the neutral review words are focussed on the products and how can they be improved.**","metadata":{}},{"cell_type":"markdown","source":"## Wordcloud-Negative reviews\n\n**Let's look at the word cloud of negative reviews**","metadata":{}},{"cell_type":"code","source":"text = review_neg[\"reviews\"]\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = stop_words).generate(str(text))\nfig = plt.figure(\n    figsize = (40, 30),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:52:41.689082Z","iopub.execute_input":"2024-06-01T22:52:41.689840Z","iopub.status.idle":"2024-06-01T22:52:53.060263Z","shell.execute_reply.started":"2024-06-01T22:52:41.689777Z","shell.execute_reply":"2024-06-01T22:52:53.058406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can see negative review words such as noisy,didnt,frickin,wasnt,snap,problems,tension etc.,**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# Extracting Features from Cleaned Reviews\n\nBefore constructing the sentiment analysis model, we need to convert the review texts into vector form, as computers cannot understand words and their sentiment directly. In this project, we'll utilize the TF-IDF method to convert the texts.","metadata":{}},{"cell_type":"markdown","source":"## Encoding target variable-sentiment\n**Let's encode our target variable with Label encoder.**","metadata":{}},{"cell_type":"code","source":"# calling the label encoder function\nlabel_encoder = preprocessing.LabelEncoder() \n  \n# Encode labels in column 'sentiment'. \nprocess_reviews['sentiment']= label_encoder.fit_transform(process_reviews['sentiment']) \n  \nprocess_reviews['sentiment'].unique() ","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:53.062905Z","iopub.execute_input":"2024-06-01T22:52:53.063634Z","iopub.status.idle":"2024-06-01T22:52:53.079171Z","shell.execute_reply.started":"2024-06-01T22:52:53.063541Z","shell.execute_reply":"2024-06-01T22:52:53.077946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_reviews['sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:53.080902Z","iopub.execute_input":"2024-06-01T22:52:53.081274Z","iopub.status.idle":"2024-06-01T22:52:53.094086Z","shell.execute_reply.started":"2024-06-01T22:52:53.081238Z","shell.execute_reply":"2024-06-01T22:52:53.092495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stemming the Reviews\n\nStemming is a method of deriving the root word from an inflected word. Here, we extract the reviews and convert the words in reviews to their root word. For example:\n* **Going -> go**\n* **Finally -> fina**\n\nNote that the root words do not necessarily carry semantic meaning. Another technique, known as Lemmatization, converts words into root words with semantic meaning. However, since it takes time, we're opting for stemming in this case.","metadata":{}},{"cell_type":"code","source":"#Extracting 'reviews' for processing\nreview_features=process_reviews.copy()\nreview_features=review_features[['reviews']].reset_index(drop=True)\nreview_features.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:53.095947Z","iopub.execute_input":"2024-06-01T22:52:53.096791Z","iopub.status.idle":"2024-06-01T22:52:53.116903Z","shell.execute_reply.started":"2024-06-01T22:52:53.096749Z","shell.execute_reply":"2024-06-01T22:52:53.115164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Performing stemming on the review dataframe\nps = PorterStemmer()\n\n#splitting and adding the stemmed words except stopwords\ncorpus = []\nfor i in range(0, len(review_features)):\n    review = re.sub('[^a-zA-Z]', ' ', review_features['reviews'][i])\n    review = review.split()\n    review = [ps.stem(word) for word in review if not word in stop_words]\n    review = ' '.join(review)\n    corpus.append(review)    ","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:52:53.118579Z","iopub.execute_input":"2024-06-01T22:52:53.118949Z","iopub.status.idle":"2024-06-01T22:53:16.554002Z","shell.execute_reply.started":"2024-06-01T22:52:53.118910Z","shell.execute_reply":"2024-06-01T22:53:16.552810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus[3]","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:53:16.555891Z","iopub.execute_input":"2024-06-01T22:53:16.556987Z","iopub.status.idle":"2024-06-01T22:53:16.564967Z","shell.execute_reply.started":"2024-06-01T22:53:16.556924Z","shell.execute_reply":"2024-06-01T22:53:16.563542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This is how a line looks like now, as computer cannot understand words and their sentiment we need to convert these words into 1's and 0's. To encode it we use TFIDF**","metadata":{}},{"cell_type":"markdown","source":"## TF-IDF (Term Frequency — Inverse Document Frequency)\n\nTF-IDF stands for \"Term Frequency — Inverse Document Frequency.\" This technique quantifies the importance of a word in documents by assigning a weight to each word. It is widely used in Information Retrieval and Text Mining.\n\nIn this implementation, we are considering bigrams (two-word combinations) and calculating their combined weight. Additionally, we are selecting only the top 5000 words from the reviews for analysis.","metadata":{}},{"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(2,2))\n# TF-IDF feature matrix\nX= tfidf_vectorizer.fit_transform(review_features['reviews'])","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:53:16.566762Z","iopub.execute_input":"2024-06-01T22:53:16.567170Z","iopub.status.idle":"2024-06-01T22:53:18.183029Z","shell.execute_reply.started":"2024-06-01T22:53:16.567114Z","shell.execute_reply":"2024-06-01T22:53:18.181676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:53:18.184714Z","iopub.execute_input":"2024-06-01T22:53:18.185136Z","iopub.status.idle":"2024-06-01T22:53:18.192312Z","shell.execute_reply.started":"2024-06-01T22:53:18.185096Z","shell.execute_reply":"2024-06-01T22:53:18.191191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we have considered 5000 words, we can confirm that we have 5000 columns from the shape.**","metadata":{}},{"cell_type":"code","source":"#Getting the target variable(encoded)\ny=process_reviews['sentiment']","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:53:18.194185Z","iopub.execute_input":"2024-06-01T22:53:18.194801Z","iopub.status.idle":"2024-06-01T22:53:18.200027Z","shell.execute_reply.started":"2024-06-01T22:53:18.194608Z","shell.execute_reply":"2024-06-01T22:53:18.198909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling Imbalance in Target Feature with SMOTE\n\nTo address the imbalance in our target feature, where we have significantly more positive sentiments compared to negative and neutral, we'll utilize SMOTE (Synthetic Minority Oversampling Technique). SMOTE aims to balance class distribution by randomly increasing minority class examples through replication.\n\nSMOTE synthesizes new minority instances between existing minority instances by linear interpolation. It generates virtual training records by randomly selecting one or more of the k-nearest neighbors for each example in the minority class. After the oversampling process, the data is reconstructed, and various classification models can be applied to the processed data.","metadata":{}},{"cell_type":"code","source":"print(f'Original dataset shape : {Counter(y)}')\n\nsmote = SMOTE(random_state=42)\nX_res, y_res = smote.fit_resample(X, y)\n\nprint(f'Resampled dataset shape {Counter(y_res)}')","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:53:18.201738Z","iopub.execute_input":"2024-06-01T22:53:18.202159Z","iopub.status.idle":"2024-06-01T22:53:18.259945Z","shell.execute_reply.started":"2024-06-01T22:53:18.202121Z","shell.execute_reply":"2024-06-01T22:53:18.258885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great, as you can see the resampled data has equally distributed classes","metadata":{}},{"cell_type":"markdown","source":"## Train-test split(75:25)\n**Using train test split function we are splitting the dataset into 75:25 ratio for train and test set respectively.**","metadata":{}},{"cell_type":"code","source":"## Divide the dataset into Train and Test\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.25, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:53:18.263756Z","iopub.execute_input":"2024-06-01T22:53:18.264114Z","iopub.status.idle":"2024-06-01T22:53:18.274688Z","shell.execute_reply.started":"2024-06-01T22:53:18.264081Z","shell.execute_reply":"2024-06-01T22:53:18.273623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-five\"></a>\n# Model Building: Sentiment Analysis\n\nNow that we've successfully processed the text data, we can treat it as a standard machine learning problem. We'll use the sparse matrix to predict the classes in the target feature.","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    thresh = cm.max() / 2.\n    for i in range (cm.shape[0]):\n        for j in range (cm.shape[1]):\n            plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:53:18.275853Z","iopub.execute_input":"2024-06-01T22:53:18.276163Z","iopub.status.idle":"2024-06-01T22:53:18.290549Z","shell.execute_reply.started":"2024-06-01T22:53:18.276133Z","shell.execute_reply":"2024-06-01T22:53:18.289515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Selection\n\nWe'll begin by selecting the best performing model using cross-validation. We'll consider all classification algorithms and perform the model selection process.","metadata":{}},{"cell_type":"code","source":"#creating the objects\nlogreg_cv = LogisticRegression(random_state=0)\ndt_cv=DecisionTreeClassifier()\nknn_cv=KNeighborsClassifier()\nsvc_cv=SVC()\nnb_cv=BernoulliNB()\ncv_dict = {0: 'Logistic Regression', 1: 'Decision Tree',2:'KNN',3:'SVC',4:'Naive Bayes'}\ncv_models=[logreg_cv,dt_cv,knn_cv,svc_cv,nb_cv]\n\n\nfor i,model in enumerate(cv_models):\n    print(\"{} Test Accuracy: {}\".format(cv_dict[i],cross_val_score(model, X, y, cv=10, scoring ='accuracy').mean()))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:53:18.292022Z","iopub.execute_input":"2024-06-01T22:53:18.292430Z","iopub.status.idle":"2024-06-01T22:56:40.588114Z","shell.execute_reply.started":"2024-06-01T22:53:18.292381Z","shell.execute_reply":"2024-06-01T22:56:40.586900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the results, we can see logistic regression outdone the rest of the algorithms and all the accuracies from the results are more than 80%. That's great. So let's go with logistic regression with hyperparameter tuning.**","metadata":{}},{"cell_type":"markdown","source":"## Logistic Regression with Hyperparameter tuning\n**We use regularization parameter and penality for parameter tuning. let's see which one to plug.**","metadata":{}},{"cell_type":"code","source":"param_grid = {'C': np.logspace(-4, 4, 50),\n             'penalty':['l1', 'l2']}\nclf = GridSearchCV(LogisticRegression(random_state=0), param_grid,cv=5, verbose=0,n_jobs=-1)\nbest_model = clf.fit(X_train,y_train)\nprint(best_model.best_estimator_)\nprint(\"The mean accuracy of the model is:\",best_model.score(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:56:40.589888Z","iopub.execute_input":"2024-06-01T22:56:40.590586Z","iopub.status.idle":"2024-06-01T22:57:51.436278Z","shell.execute_reply.started":"2024-06-01T22:56:40.590536Z","shell.execute_reply":"2024-06-01T22:57:51.434561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the selected params, we get accuracy. Let's plug and chug**","metadata":{}},{"cell_type":"code","source":"logreg = LogisticRegression(C=10000.0, random_state=0)\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:57:51.440741Z","iopub.execute_input":"2024-06-01T22:57:51.441526Z","iopub.status.idle":"2024-06-01T22:57:52.740133Z","shell.execute_reply.started":"2024-06-01T22:57:51.441466Z","shell.execute_reply":"2024-06-01T22:57:52.738785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have got 94% accuracy. That ain't bad. But for classification problems we need to get confusion matrix and check f1 score rather than accuracy**","metadata":{}},{"cell_type":"markdown","source":"## Classification metrics\n**Here we plot the confusion matrix with ROC and check our f1 score**","metadata":{}},{"cell_type":"code","source":"cm = metrics.confusion_matrix(y_test, y_pred)\nplot_confusion_matrix(cm, classes=['Negative','Neutral','Positive'])","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:57:52.742042Z","iopub.execute_input":"2024-06-01T22:57:52.742859Z","iopub.status.idle":"2024-06-01T22:57:53.053206Z","shell.execute_reply.started":"2024-06-01T22:57:52.742806Z","shell.execute_reply":"2024-06-01T22:57:53.052157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Check out the diagonal elements(2326+2195+1854), they are correctly predicted records and rest are incorrectly classified by the algorithm**","metadata":{}},{"cell_type":"code","source":"print(\"Classification Report:\\n\",classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T22:57:53.054634Z","iopub.execute_input":"2024-06-01T22:57:53.054967Z","iopub.status.idle":"2024-06-01T22:57:53.076091Z","shell.execute_reply.started":"2024-06-01T22:57:53.054936Z","shell.execute_reply":"2024-06-01T22:57:53.075198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Since predicting both positive,negative and neutral reviews are important we are considering.We got a pretty good f1 score. As we see it got a good score across all classes classified **","metadata":{}},{"cell_type":"markdown","source":"## ROC-AUC Curve\n\nThe ROC-AUC curve is crucial for determining the optimal threshold based on objective criteria. It provides insights into how well each class was classified. Additionally, we plot micro and macro averages on the ROC curve.\n\n- **ROC Curve**: Plots the true positive rate against the false positive rate for different threshold values, providing a visual representation of the model's performance across various thresholds.\n  \n- **Micro Average**: Computes the aggregate true positive rate and false positive rate across all classes, treating each instance equally. It's useful for imbalanced datasets.\n  \n- **Macro Average**: Computes the true positive rate and false positive rate for each class independently and then averages them. It provides equal weight to each class, regardless of class imbalance.\n\nThe ROC-AUC curve assists in understanding the classification performance of the model and determining an appropriate threshold for decision-making.","metadata":{}},{"cell_type":"code","source":"#Binarizing the target feature\ny = label_binarize(y, classes=[0, 1, 2])\nn_classes = y.shape[1]\n\n#Train-Test split(80:20)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,\n                                                    random_state=0)\n\n#OneVsRestClassifier\nclassifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n                                 random_state=10))\ny_score = classifier.fit(X_train, y_train).decision_function(X_test)\n\n#Computing TPR and FPR\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n    \n# aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=4,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=4)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-01T22:57:53.077800Z","iopub.execute_input":"2024-06-01T22:57:53.078158Z","iopub.status.idle":"2024-06-01T22:58:33.249518Z","shell.execute_reply.started":"2024-06-01T22:57:53.078125Z","shell.execute_reply":"2024-06-01T22:58:33.248118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insights:**\n- **ROC Curve Analysis**: Classes 2 and 0 exhibit excellent classification performance, as indicated by their high area under the curve. Optimal threshold selection can be between 0.6-0.8 to achieve a balanced trade-off between true positive rate (TPR) and false positive rate (FPR).\n  \n- **Micro and Macro Average Comparison**: Micro average performs exceptionally well, while macro average yields a relatively lower score. \n  - **Micro-Average**: Aggregates contributions of all classes, treating each equally. \n  - **Macro-Average**: Computes the metric independently for each class and then averages them. In a multi-class classification setup, micro-average is preferable if class imbalance is suspected.\n\nThese insights guide us in understanding the classification performance and selecting an appropriate threshold for decision-making.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}